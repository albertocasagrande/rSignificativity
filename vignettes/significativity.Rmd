---
title: "Statistical Coefficient Significativity"
output: rmarkdown::html_vignette
description: >
  Measuring the significativity of a statistical coefficient
vignette: >
  %\VignetteIndexEntry{Statistical Coefficient Significativity}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  markdown:
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Statistical coefficients, such as Cohen's $\kappa$ and
$\textrm{IA}*$, measures the agreement between two discrete
classifiers mapping confusion matrices into real values.
When a golden standard classifier is available,
the best one among a set of classifiers can be selected
by picking the one whose confusion matrix with respect to
the golden standard has the maximal statistical coefficient
value.

However, the statistical coefficient values alone lack of a
meaningfulness indication. Understanding whether
two classifiers significantly agree on the considered
dataset is not possible by simply looking at the
corresponding statistical coefficient value.

Let $\mathcal{M}_{n,m}$ be the set of
$n \times n$-confusion matrices built over a dataset
having size $m$, i.e., the elements of any matrix
$\mathcal{M}_{n,m}$ sum up to $m$.
For any statistical coefficient $\sigma$, the
$\sigma$-significativity of $c$ in $\mathcal{M}_{n,m}$ is
$$
\varrho_{\sigma, n, m}(c) \stackrel{\tiny\textrm{def}}{=} \frac{\left|\left\{M \in \mathcal{M}_{n,m} \, |\, \sigma(M) \leq c\right\}\right|}{\left|\mathcal{M}_{n,m}\right|}.
$$
The $\sigma$-significativity measures the number of matrices
in $\mathcal{M}_{n,m}$ having a $\sigma$-value smaller or equal to $c$.
From a different point of view,  $\varrho_{\sigma, n, m}(c)$ is
the probability to choose by chance a matrix whose $\sigma$-value smaller or equal to $c$.

Since $|\mathcal{M}_{n,m}|=\binom{n^2+m-1}{m}$, computing $\varrho_{\sigma, n, m}(c)$
takes time $O\left(n^2\binom{n^2+m-1}{m}\right)$. However, $\varrho_{\sigma, n, m}(c)$
can be estimated by using the Monte Carlo method with $N$ samples in time $\Theta(N(n^2+m))$.

The function `M_significativity()` lets us to both exactly compute $\varrho_{\sigma, n, m}(c)$
and estimate it by using the Monte Carlo method.

```{r}
library("rSignificativity")

kappa <- function(conf_matrix) {
  p_o <- sum(diag(conf_matrix)) / sum(conf_matrix)

  # Calculate the expected agreement (P_e)
  row_totals <- rowSums(conf_matrix)
  col_totals <- colSums(conf_matrix)
  total <- sum(conf_matrix)
  p_e <- sum((row_totals * col_totals) / total^2)

  # Calculate Cohen's kappa
  kappa <- (p_o - p_e) / (1 - p_e)

  return(kappa)
}

# evaluate kappa-significativity of 0.5 in M_{2,100} with 10000 samples
M_significativity(kappa, n = 2, m = 100, c = 0.5)

# evaluate kappa-significativity of 0.5 in M_{2,100} with 1000 samples
M_significativity(kappa, n = 2, m = 100, c = 0.5, number_of_samples = 1000)

# evaluate kappa-significativity of 0.5 in M_{2,100} with 1000 samples
M_significativity(kappa, n = 2, m = 100, c = 0.5, number_of_samples = 1000)

# exactly compute kappa-significativity of 0.5 in M_{2,5}
M_significativity(kappa, n = 2, m = 100, c = 0.5, number_of_samples = NULL)
```

The $\sigma$-significativity of $c$ in $\mathcal{P}_{n}$,
where $\mathcal{P}_{n}$ is the set of all the $n \times n$-probability
matrices, is
$$
\rho_{\sigma, n}(c) \stackrel{\tiny\textrm{def}}{=} \frac{V\left(\left\{M \in \mathcal{P}_{n} \, |\, \sigma(M) \leq c\right\}\right)}{V(\Delta^{(n^2-1)})}
$$
where $\Delta^{(n^2-1)}$ is $n^2$-dimensional probability simplex and $V(\cdot)$ is the $n^2-1$-dimensional Lebesgue measure.

If $\sigma(M) \leq c$ is definable in an o-minimal theory, such as in the case
of Cohen's $\kappa$ and $\textrm{IA}*$, then
$$
\lim_{m \rightarrow +\infty}\varrho_{\sigma, n, m}(c) = \rho_{\sigma, n}(c).
$$


We can estimate $\rho_{\sigma, n}(c)$ by
using the Monte Carlo method with $N$ samples in time $\Theta(n^2 N)$.
The function `P_significativity()` implements this algorithm.

```{r}
# evaluate kappa-significativity of 0.5 in P_{2} with 10000 samples
P_significativity(kappa, n = 2, c = 0.5)

# evaluate kappa-significativity of 0.5 in P_{2} with 1000 samples
P_significativity(kappa, n = 2, c = 0.5, number_of_samples = 1000)

# evaluate kappa-significativity of 0.5 in P_{2} with 1000 samples
P_significativity(kappa, n = 2, c = 0.5, number_of_samples = 1000)
```